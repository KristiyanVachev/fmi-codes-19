{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "from pathlib import Path\n",
    "\n",
    "def dumpPickle(fileName, content):\n",
    "    pickleFile = open(fileName, 'wb')\n",
    "    cPickle.dump(content, pickleFile, -1)\n",
    "    pickleFile.close()\n",
    "\n",
    "def loadPickle(fileName):    \n",
    "    file = open(fileName, 'rb')\n",
    "    content = cPickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return content\n",
    "    \n",
    "def pickleExists(fileName):\n",
    "    file = Path(fileName)\n",
    "    \n",
    "    if file.is_file():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "def printBold(string):\n",
    "    display(Markdown('**' + string + '**'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#There seems to be a bug with spacy's stop words.\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "for word in STOP_WORDS:\n",
    "    for w in (word, word[0].capitalize(), word.upper()):\n",
    "        lex = nlp.vocab[w]\n",
    "        lex.is_stop = True\n",
    "        \n",
    "#Extract answers and the sentence they are in\n",
    "def extractAnswers(qas, doc):\n",
    "    answers = []\n",
    "\n",
    "    senStart = 0\n",
    "    senId = 0\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        senLen = len(sentence.text)\n",
    "\n",
    "        for answer in qas:\n",
    "            answerStart = answer['answers'][0]['answer_start']\n",
    "\n",
    "            if (answerStart >= senStart and answerStart < (senStart + senLen)):\n",
    "                answers.append({'sentenceId': senId, 'text': answer['answers'][0]['text']})\n",
    "\n",
    "        senStart += senLen\n",
    "        senId += 1\n",
    "    \n",
    "    return answers\n",
    "\n",
    "#TODO - Clean answers from stopwords?\n",
    "def tokenIsAnswer(token, sentenceId, answers):\n",
    "    for i in range(len(answers)):\n",
    "        if (answers[i]['sentenceId'] == sentenceId):\n",
    "            if (answers[i]['text'] == token):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "#Save named entities start points\n",
    "\n",
    "def getNEStartIndexs(doc):\n",
    "    neStarts = {}\n",
    "    for ne in doc.ents:\n",
    "        neStarts[ne.start] = ne\n",
    "        \n",
    "    return neStarts \n",
    "\n",
    "def getSentenceStartIndexes(doc):\n",
    "    senStarts = []\n",
    "    \n",
    "    for sentence in doc.sents:\n",
    "        senStarts.append(sentence[0].i)\n",
    "    \n",
    "    return senStarts\n",
    "    \n",
    "def getSentenceForWordPosition(wordPos, senStarts):\n",
    "    for i in range(1, len(senStarts)):\n",
    "        if (wordPos < senStarts[i]):\n",
    "            return i - 1\n",
    "        \n",
    "def addWordsForParagrapgh(newWords, text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    neStarts = getNEStartIndexs(doc)\n",
    "    senStarts = getSentenceStartIndexes(doc)\n",
    "    \n",
    "    #index of word in spacy doc text\n",
    "    i = 0\n",
    "    \n",
    "    while (i < len(doc)):\n",
    "        #If the token is a start of a Named Entity, add it and push to index to end of the NE\n",
    "        if (i in neStarts):\n",
    "            word = neStarts[i]\n",
    "            #add word\n",
    "            currentSentence = getSentenceForWordPosition(word.start, senStarts)\n",
    "            wordLen = word.end - word.start\n",
    "            shape = ''\n",
    "            for wordIndex in range(word.start, word.end):\n",
    "                shape += (' ' + doc[wordIndex].shape_)\n",
    "\n",
    "            newWords.append([word.text,\n",
    "                            0,\n",
    "                            0,\n",
    "                            currentSentence,\n",
    "                            wordLen,\n",
    "                            word.label_,\n",
    "                            None,\n",
    "                            None,\n",
    "                            None,\n",
    "                            shape])\n",
    "            i = neStarts[i].end - 1\n",
    "        #If not a NE, add the word if it's not a stopword or a non-alpha (not regular letters)\n",
    "        else:\n",
    "            if (doc[i].is_stop == False and doc[i].is_alpha == True):\n",
    "                word = doc[i]\n",
    "\n",
    "                currentSentence = getSentenceForWordPosition(i, senStarts)\n",
    "                wordLen = 1\n",
    "\n",
    "                newWords.append([word.text,\n",
    "                                0,\n",
    "                                0,\n",
    "                                currentSentence,\n",
    "                                wordLen,\n",
    "                                None,\n",
    "                                word.pos_,\n",
    "                                word.tag_,\n",
    "                                word.dep_,\n",
    "                                word.shape_])\n",
    "        i += 1\n",
    "\n",
    "def oneHotEncodeColumns(df):\n",
    "    columnsToEncode = ['NER', 'POS', \"TAG\", 'DEP']\n",
    "\n",
    "    for column in columnsToEncode:\n",
    "        one_hot = pd.get_dummies(df[column])\n",
    "        one_hot = one_hot.add_prefix(column + '_')\n",
    "\n",
    "        df = df.drop(column, axis = 1)\n",
    "        df = df.join(one_hot)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDf(text):\n",
    "    words = []\n",
    "    addWordsForParagrapgh(words, text)\n",
    "\n",
    "    wordColums = ['text', 'titleId', 'paragrapghId', 'sentenceId','wordCount', 'NER', 'POS', 'TAG', 'DEP','shape']\n",
    "    df = pd.DataFrame(words, columns=wordColums)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDf(df):\n",
    "    #One-hot encoding\n",
    "    wordsDf = oneHotEncodeColumns(df)\n",
    "\n",
    "    #Drop unused columns\n",
    "    columnsToDrop = ['text', 'titleId', 'paragrapghId', 'sentenceId', 'shape']\n",
    "    wordsDf = wordsDf.drop(columnsToDrop, axis = 1)\n",
    "\n",
    "    #Add missing colums \n",
    "    predictorColumns = ['wordCount','NER_CARDINAL','NER_DATE','NER_EVENT','NER_FAC','NER_GPE','NER_LANGUAGE','NER_LAW','NER_LOC','NER_MONEY','NER_NORP','NER_ORDINAL','NER_ORG','NER_PERCENT','NER_PERSON','NER_PRODUCT','NER_QUANTITY','NER_TIME','NER_WORK_OF_ART','POS_ADJ','POS_ADP','POS_ADV','POS_CCONJ','POS_DET','POS_INTJ','POS_NOUN','POS_NUM','POS_PART','POS_PRON','POS_PROPN','POS_PUNCT','POS_SYM','POS_VERB','POS_X','TAG_''','TAG_-LRB-','TAG_.','TAG_ADD','TAG_AFX','TAG_CC','TAG_CD','TAG_DT','TAG_EX','TAG_FW','TAG_IN','TAG_JJ','TAG_JJR','TAG_JJS','TAG_LS','TAG_MD','TAG_NFP','TAG_NN','TAG_NNP','TAG_NNPS','TAG_NNS','TAG_PDT','TAG_POS','TAG_PRP','TAG_PRP$','TAG_RB','TAG_RBR','TAG_RBS','TAG_RP','TAG_SYM','TAG_TO','TAG_UH','TAG_VB','TAG_VBD','TAG_VBG','TAG_VBN','TAG_VBP','TAG_VBZ','TAG_WDT','TAG_WP','TAG_WRB','TAG_XX','DEP_ROOT','DEP_acl','DEP_acomp','DEP_advcl','DEP_advmod','DEP_agent','DEP_amod','DEP_appos','DEP_attr','DEP_aux','DEP_auxpass','DEP_case','DEP_cc','DEP_ccomp','DEP_compound','DEP_conj','DEP_csubj','DEP_csubjpass','DEP_dative','DEP_dep','DEP_det','DEP_dobj','DEP_expl','DEP_intj','DEP_mark','DEP_meta','DEP_neg','DEP_nmod','DEP_npadvmod','DEP_nsubj','DEP_nsubjpass','DEP_nummod','DEP_oprd','DEP_parataxis','DEP_pcomp','DEP_pobj','DEP_poss','DEP_preconj','DEP_predet','DEP_prep','DEP_prt','DEP_punct','DEP_quantmod','DEP_relcl','DEP_xcomp']\n",
    "\n",
    "    for feature in predictorColumns:\n",
    "        if feature not in wordsDf.columns:\n",
    "            wordsDf[feature] = 0\n",
    "    \n",
    "    return wordsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWords(wordsDf, df):\n",
    "    \n",
    "    predictorPickleName = 'pickles/predictor-spacy-features.pkl'\n",
    "    predictor = loadPickle(predictorPickleName)\n",
    "    \n",
    "    y_pred = predictor.predict_proba(wordsDf)\n",
    "\n",
    "    labeledAnswers = []\n",
    "    for i in range(len(y_pred)):\n",
    "        labeledAnswers.append({'word': df.iloc[i]['text'], 'prob': y_pred[i][0]})\n",
    "    \n",
    "    return labeledAnswers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blankAnswer(firstTokenIndex, lastTokenIndex, sentStart, sentEnd, doc):\n",
    "    leftPartStart = doc[sentStart].idx\n",
    "    leftPartEnd = doc[firstTokenIndex].idx\n",
    "    rightPartStart = doc[lastTokenIndex].idx + len(doc[lastTokenIndex])\n",
    "    rightPartEnd = doc[sentEnd - 1].idx + len(doc[sentEnd - 1])\n",
    "    \n",
    "    question = doc.text[leftPartStart:leftPartEnd] + '_____' + doc.text[rightPartStart:rightPartEnd]\n",
    "    \n",
    "    return question\n",
    "    \n",
    "    \n",
    "   #for i in range(sentEnd - sentStart):\n",
    "   #    if sentStart + i != tokenIndex\n",
    "   #    print(doc[13 + i])\n",
    "   #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addQuestions(answers, text):\n",
    "    doc = nlp(text)\n",
    "    currAnswerIndex = 0\n",
    "    qaPair = []\n",
    "\n",
    "    #Check wheter each token is the next answer\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            \n",
    "            #If all the answers have been found, stop looking\n",
    "            if currAnswerIndex >= len(answers):\n",
    "                break\n",
    "            \n",
    "            #In the case where the answer is consisted of more than one token, check the following tokens as well.\n",
    "            answerDoc = nlp(answers[currAnswerIndex]['word'])\n",
    "            answerIsFound = True\n",
    "            \n",
    "            for j in range(len(answerDoc)):\n",
    "                if token.i + j >= len(doc) or doc[token.i + j].text != answerDoc[j].text:\n",
    "                    answerIsFound = False\n",
    "           \n",
    "            #If the current token is corresponding with the answer, add it \n",
    "            if answerIsFound:\n",
    "                question = blankAnswer(token.i, token.i + len(answerDoc) - 1, sent.start, sent.end, doc)\n",
    "                \n",
    "                qaPair.append({'question' : question, 'answer': answers[currAnswerIndex]['word'], 'prob': answers[currAnswerIndex]['prob']})\n",
    "                \n",
    "                currAnswerIndex += 1\n",
    "                \n",
    "    return qaPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortAnswers(qaPairs):\n",
    "    orderedQaPairs = sorted(qaPairs, key=lambda qaPair: qaPair['prob'])\n",
    "    \n",
    "    return orderedQaPairs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_file = 'data\\embeddings\\glove.6B.300d.txt'\n",
    "tmp_file = \"data\\embeddings\\word2vec-glove.6B.300d.txt\"\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDistractors(sentence, answer, count):\n",
    "    answer = str.lower(answer)\n",
    "    \n",
    "    ##Extracting closest words for the answer. \n",
    "    try:\n",
    "        closestWords = model.most_similar(positive=[answer], topn=count)\n",
    "    except:\n",
    "        #In case the word is not in the vocabulary, or other problem not loading embeddings\n",
    "        return []\n",
    "\n",
    "    #Return count many distractors\n",
    "    distractors = []\n",
    "    for i in range(count):\n",
    "        if i >= len(closestWords):\n",
    "            break\n",
    "            \n",
    "        distractors.append(closestWords[i][0])\n",
    "        \n",
    "    return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['probo', 'koalas', 'orangutan', 'grizzly', 'marsupial']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateDistractors(\"Koala is cool\", \"Koala\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDistractors(qaPairs, count):\n",
    "    for qaPair in qaPairs:\n",
    "        distractors = generateDistractors(qaPair['question'], qaPair['answer'], count)\n",
    "        qaPair['distractors'] = distractors\n",
    "    \n",
    "    return qaPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQuestions(text, count, isTest):\n",
    "    \n",
    "    df = generateDf(text)\n",
    "    wordsDf = prepareDf(df)\n",
    "    labeledAnswers = predictWords(wordsDf, df)\n",
    "    qaPairs = addQuestions(labeledAnswers, text)\n",
    "    orderedQaPairs = sortAnswers(qaPairs)\n",
    "    questions = addDistractors(orderedQaPairs[:count], 4)\n",
    "\n",
    "    for i in range(count):\n",
    "        display(Markdown('### Question ' + str(i + 1) + ':'))\n",
    "        print(questions[i]['question'])\n",
    "        if isTest:\n",
    "            answers = questions[i]['distractors']\n",
    "            answers.append(questions[i]['answer'])\n",
    "            \n",
    "            display(Markdown('#### Answers:'))\n",
    "            for answer in sorted(answers):\n",
    "                print(str.lower(answer))\n",
    "                \n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            display(Markdown('~~<sub>' + questions[i]['answer'][::-1] + '<sub>~~'))\n",
    "        else:\n",
    "            display(Markdown('#### Answer:'))\n",
    "            print(questions[i]['answer'])\n",
    "            display(Markdown('#### Incorrect answers:'))\n",
    "            for distractor in questions[i]['distractors']:\n",
    "                print(distractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Question 1:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At standard temperature and pressure, two _____ of the element bind to form dioxygen, a colorless and odorless diatomic gas with the formula O2.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atoms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molecules\n",
      "electrons\n",
      "ions\n",
      "atom\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 2:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxygen is a chemical _____ with symbol O and atomic number 8.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elements\n",
      "component\n",
      "aspect\n",
      "dimension\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 3:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a _____ of the chalcogen group on the periodic table, a highly reactive nonmetal, and an oxidizing agent that readily forms oxides with most elements as well as with other compounds.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "members\n",
      "elected\n",
      "committee\n",
      "council\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 4:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By mass, oxygen is the third-most abundant _____ in the universe, after hydrogen and helium.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elements\n",
      "component\n",
      "aspect\n",
      "dimension\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 5:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By mass, _____ is the third-most abundant element in the universe, after hydrogen and helium.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxygen\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hydrogen\n",
      "nitrogen\n",
      "helium\n",
      "nutrients\n"
     ]
    }
   ],
   "source": [
    "text = \"Oxygen is a chemical element with symbol O and atomic number 8. It is a member of the chalcogen group on the periodic table, a highly reactive nonmetal, and an oxidizing agent that readily forms oxides with most elements as well as with other compounds. By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium. At standard temperature and pressure, two atoms of the element bind to form dioxygen, a colorless and odorless diatomic gas with the formula O2. Diatomic oxygen gas constitutes 20.8% of the Earth's atmosphere. As compounds including oxides, the element makes up almost half of the Earth's crust.\"\n",
    "\n",
    "generateQuestions(text, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addQuestionsJson(answers, text):\n",
    "    doc = nlp(text)\n",
    "    currAnswerIndex = 0\n",
    "    qaPair = []\n",
    "    \n",
    "    with open('data/most-common.txt') as f:\n",
    "        mostCommon = f.readlines()\n",
    "        mostCommon = [x.strip() for x in mostCommon] \n",
    "\n",
    "    #Check wheter each token is the next answer\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            \n",
    "            #If all the answers have been found, stop looking\n",
    "            if currAnswerIndex >= len(answers):\n",
    "                break\n",
    "            \n",
    "            #In the case where the answer is consisted of more than one token, check the following tokens as well.\n",
    "            answerDoc = nlp(answers[currAnswerIndex]['word'])\n",
    "            answerIsFound = True\n",
    "            \n",
    "            for j in range(len(answerDoc)):\n",
    "                if token.i + j >= len(doc) or doc[token.i + j].text != answerDoc[j].text:\n",
    "                    answerIsFound = False\n",
    "           \n",
    "            #If the current token is corresponding with the answer, add it \n",
    "            if answerIsFound:\n",
    "                #question = blankAnswerJson(token.i, token.i + len(answerDoc) - 1, sent.start, sent.end, doc)\n",
    "                \n",
    "                leftPartStart = doc[sent.start].idx\n",
    "                rightPartEnd = doc[sent.end - 1].idx + len(doc[sent.end - 1])\n",
    "                sentence = doc.text[leftPartStart:rightPartEnd]\n",
    "                \n",
    "                #if True:\n",
    "                if answers[currAnswerIndex]['word'] not in mostCommon:\n",
    "                    qaPair.append({'question' : sentence,\n",
    "                                   'answer': answers[currAnswerIndex]['word'], \n",
    "                                   'prob': answers[currAnswerIndex]['prob'], \n",
    "                                   'startIndex': doc[token.i].idx - leftPartStart})\n",
    "\n",
    "                currAnswerIndex += 1\n",
    "                \n",
    "    return qaPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupSentences(qaPairs):\n",
    "    sentences = {}\n",
    "    json = []\n",
    "    \n",
    "    for qaPair in qaPairs:\n",
    "        sentences[qaPair['question']] = {'text': qaPair['question'], 'answers': []}\n",
    "        \n",
    "    for qaPair in qaPairs:\n",
    "        sentences[qaPair['question']]['answers'].append({'correct': qaPair['answer'], 'startIndex': qaPair['startIndex'], 'confidence': qaPair['prob'], 'distractors': qaPair['distractors']}) \n",
    "        \n",
    "    for sentence in sentences:\n",
    "        json.append(sentences[sentence])\n",
    "        \n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateJson(text, count):\n",
    "    \n",
    "    df = generateDf(text)\n",
    "    wordsDf = prepareDf(df)\n",
    "    labeledAnswers = predictWords(wordsDf, df)\n",
    "    qaPairs = addQuestionsJson(labeledAnswers, text)\n",
    "    orderedQaPairs = sortAnswers(qaPairs)\n",
    "    questions = addDistractors(orderedQaPairs[:count], 4)\n",
    "    sentences = groupSentences(questions)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#text = \"Oxygen is a chemical element with symbol O and atomic number 8. It is a member of the chalcogen group on the periodic table, a highly reactive nonmetal, and an oxidizing agent that readily forms oxides with most elements as well as with other compounds. By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium. At standard temperature and pressure, two atoms of the element bind to form dioxygen, a colorless and odorless diatomic gas with the formula O2. Diatomic oxygen gas constitutes 20.8% of the Earth's atmosphere. As compounds including oxides, the element makes up almost half of the Earth's crust.\"\n",
    "\n",
    "text = \"\"\"Early experiments\n",
    "One of the first known experiments on the relationship between combustion and air was conducted by the 2nd century BCE Greek writer on mechanics, Philo of Byzantium. In his work Pneumatica, Philo observed that inverting a vessel over a burning candle and surrounding the vessel's neck with water resulted in some water rising into the neck.[2] Philo incorrectly surmised that parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass. Many centuries later Leonardo da Vinci built on Philo's work by observing that a portion of air is consumed during combustion and respiration.[3]\n",
    "\n",
    "In the late 17th century, Robert Boyle proved that air is necessary for combustion. English chemist John Mayow (1641–1679) refined this work by showing that fire requires only a part of air that he called spiritus nitroaereus.[4] In one experiment, he found that placing either a mouse or a lit candle in a closed container over water caused the water to rise and replace one-fourteenth of the air's volume before extinguishing the subjects.[5] From this he surmised that nitroaereus is consumed in both respiration and combustion.\n",
    "\n",
    "Mayow observed that antimony increased in weight when heated, and inferred that the nitroaereus must have combined with it.[4] He also thought that the lungs separate nitroaereus from air and pass it into the blood and that animal heat and muscle movement result from the reaction of nitroaereus with certain substances in the body.[4] Accounts of these and other experiments and ideas were published in 1668 in his work Tractatus duo in the tract \"De respiratione\".[5]\n",
    "\n",
    "Phlogiston theory\n",
    "Main article: Phlogiston theory\n",
    "Robert Hooke, Ole Borch, Mikhail Lomonosov, and Pierre Bayen all produced oxygen in experiments in the 17th and the 18th century but none of them recognized it as a chemical element.[6] This may have been in part due to the prevalence of the philosophy of combustion and corrosion called the phlogiston theory, which was then the favored explanation of those processes.[7]\n",
    "\n",
    "Established in 1667 by the German alchemist J. J. Becher, and modified by the chemist Georg Ernst Stahl by 1731,[8] phlogiston theory stated that all combustible materials were made of two parts. One part, called phlogiston, was given off when the substance containing it was burned, while the dephlogisticated part was thought to be its true form, or calx.[3]\n",
    "\n",
    "Highly combustible materials that leave little residue, such as wood or coal, were thought to be made mostly of phlogiston; non-combustible substances that corrode, such as iron, contained very little. Air did not play a role in phlogiston theory, nor were any initial quantitative experiments conducted to test the idea; instead, it was based on observations of what happens when something burns, that most common objects appear to become lighter and seem to lose something in the process.[3]\n",
    "\n",
    "Discovery\n",
    "A drawing of an elderly man sitting by a table and facing parallel to the drawing. His left arm rests on a notebook, legs crossed.\n",
    "Joseph Priestley is usually given priority in the discovery.\n",
    "Polish alchemist, philosopher, and physician Michael Sendivogius in his work De Lapide Philosophorum Tractatus duodecim e naturae fonte et manuali experientia depromti (1604) described a substance contained in air, referring to it as 'cibus vitae' (food of life[9]), and this substance is identical with oxygen.[10] Sendivogius, during his experiments performed between 1598 and 1604, properly recognized that the substance is equivalent to the gaseous byproduct released by the thermal decomposition of potassium nitrate. In Bugaj’s view, the isolation of oxygen and the proper association of the substance to that part of air which is required for life, lends sufficient weight to the discovery of oxygen by Sendivogius.[10] This discovery of Sendivogius was however frequently denied by the generations of scientists and chemists which succeeded him.[9]\n",
    "\n",
    "It is also commonly claimed that oxygen was first discovered by Swedish pharmacist Carl Wilhelm Scheele. He had produced oxygen gas by heating mercuric oxide and various nitrates in 1771–2.[11][12][3] Scheele called the gas \"fire air\" because it was then the only known agent to support combustion. He wrote an account of this discovery in a manuscript titled Treatise on Air and Fire, which he sent to his publisher in 1775. That document was published in 1777.[13]\n",
    "\n",
    "In the meantime, on August 1, 1774, an experiment conducted by the British clergyman Joseph Priestley focused sunlight on mercuric oxide (HgO) contained in a glass tube, which liberated a gas he named \"dephlogisticated air\".[12] He noted that candles burned brighter in the gas and that a mouse was more active and lived longer while breathing it. After breathing the gas himself, Priestley wrote: \"The feeling of it to my lungs was not sensibly different from that of common air, but I fancied that my breast felt peculiarly light and easy for some time afterwards.\"[6] Priestley published his findings in 1775 in a paper titled \"An Account of Further Discoveries in Air,\" which was included in the second volume of his book titled Experiments and Observations on Different Kinds of Air.[3][14] Because he published his findings first, Priestley is usually given priority in the discovery.\n",
    "\n",
    "The French chemist Antoine Laurent Lavoisier later claimed to have discovered the new substance independently. Priestley visited Lavoisier in October 1774 and told him about his experiment and how he liberated the new gas. Scheele also dispatched a letter to Lavoisier on September 30, 1774, that described his discovery of the previously unknown substance, but Lavoisier never acknowledged receiving it (a copy of the letter was found in Scheele's belongings after his death).[13]\n",
    "\n",
    "Lavoisier's contribution\"\"\"\n",
    "generateJson(text, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def trimSquareBrackets(text):\n",
    "    return re.sub(r'\\[(.*?)\\]', lambda L: '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9002/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [24/Mar/2019 13:45:42] \"POST /generate?text=Wikipedia%20%28/ˌwɪkɪˈpiːdiə/%20%28About%20this%20soundlisten%29,%20/ˌwɪkiˈpiːdiə/%20%28About%20this%20soundlisten%29%20WIK-ih-PEE-dee-ə%29%20is%20a%20multilingual,%20web-based,%20free%20encyclopedia%20based%20on%20a%20model%20of%20openly%20editable%20and%20viewable%20content,%20a%20wiki.%20It%20is%20the%20largest%20and%20most%20popular%20general%20reference%20work%20on%20the%20World%20Wide%20Web,[3][4][5]%20and%20is%20one%20of%20the%20most%20popular%20websites%20by%20Alexa%20rank.[6]%20It%20is%20owned%20and%20supported%20by%20the%20Wikimedia%20Foundation,%20a%20non-profit%20organization%20that%20operates%20on%20money%20it%20receives%20from%20donors.[7][8][9] HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from werkzeug.wrappers import Request, Response\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return ''.join(map(str, generateJson(text, 20)))\n",
    "\n",
    "@app.route(\"/generate\", methods=[\"POST\"])\n",
    "def test():\n",
    "    return json.dumps(generateJson(trimSquareBrackets(text), 20))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9002, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
